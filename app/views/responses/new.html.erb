<h1>Record an interview</h1>
<h2>Your question: <%= @question.content %></h2>

<div class="canvasContainer">
  <canvas id="canvas" width="300" height="300"></canvas>
</div>

<i id="startRecording" class="big-mic fa fa-microphone fa-4x "></i>

<div id="on-recording">
</div>

<div id="recording">
  <%= form_for @response do |f| %>
    <%= f.text_area :transcript, id: "results", value: "Transcript goes here" %>
    <%= render "shared/error_messages", obj: @response, col: :transcript %>
    <h3 id="endRecording">Click here to end recording</h3>
    <%= f.submit "Submit", id: "submit" %>
  <% end %>
</div>

<script charset="utf-8">
//
// // REBECCA DON'T FORGET TO MOVE THIS TO A BETTER PLACE SOON
// // AND/OR INTEGRATE WITH TRANSCRIPTION CLICK FUNCITONS
//
$(document).ready(function() {

  var contextClass = (window.AudioContext ||
    window.webkitAudioContext ||
    window.mozAudioContext ||
    window.oAudioContext ||
    window.msAudioContext);
    if (contextClass) {
      // Web Audio API is available.
      var context = new contextClass();
    } else {
      // Web Audio API is not available. Ask the user to use a supported browser.
      alert("Please switch to Google Chrome v. 25 and up or Safari v. 7.1 and up.")
    }

    function getAverageVolume(array) {
      var values = 0;
      // get all the frequency??? amplitudes
      for (var i = 0; i < array.length; i++) {
        values += array[i];
      }
      return values / (array.length);
    }

    // Get canvas
    function getCanvas() {
      return document.getElementById('canvas');
    }

    // This gets called when drawwing square for each side.
    function canvasDrawLine(oPosX, oPosY, fPosX, fPosY) {
      var ctx = getCanvas().getContext('2d');
      ctx.beginPath();
      ctx.moveTo(oPosX, oPosY);
      ctx.lineTo(fPosX, fPosY);
      ctx.stroke();
    }

    // Drawing the actual square shape
    function canvasDrawSquare(ulPosX, ulPosY, lrPosX, lrPosY) {
      canvasDrawLine(ulPosX, ulPosY, ulPosX, lrPosY);
      canvasDrawLine(ulPosX, lrPosY, lrPosX, lrPosY);
      canvasDrawLine(lrPosX, lrPosY, lrPosX, ulPosY);
      canvasDrawLine(lrPosX, ulPosY, ulPosX, ulPosY);
    }

    // Drawing a circle
    function canvasDrawCircle(average){
      var ctx = canvas.getContext('2d');
      ctx.beginPath();
      // x position, y position, radius, unknown, arc in radians.
      ctx.arc(150, 150, average, 0, 2 * Math.PI, false);
      ctx.lineWidth = 1; // border for circle
      ctx.strokeStyle = '#FF4C4C'; // beautiful coral
      ctx.stroke();
    }

    function canvasInitialize(width, height) {
      // Set canvas parameters
      getCanvas().width = width;
      getCanvas().height = height;

      // Outline of canvas
      //getCanvas().getContext('2d').clearRect(0,0,width,height);
      //canvasDrawSquare(0,0,width,height);
    }

    function onSuccess(stream) {
      var context = new webkitAudioContext();
      var mediaStreamSource = context.createMediaStreamSource(stream);

      var analyser = context.createAnalyser();
      analyser.smoothingTimeConstant = 0.7;
      analyser.fftSize = 1024;

      var javascriptNode = context.createScriptProcessor(2048, 1, 1);

      javascriptNode.onaudioprocess = function(e) {
        //var sample = e.inputBuffer.getChannelData(0);

        // get the average, bincount is fftsize / 2
        var array =  new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(array);

        // calculate average volume
        var average = getAverageVolume(array)

        // print value out (Not including this for now)
        // log(average);

        // create canvas
        canvasInitialize(300,300);

        // draw green bar
        getCanvas().getContext('2d').strokeStyle='#000000';
        getCanvas().getContext('2d').strokeStyle='#00ff00';
        // By changing the multiplication, you can change relative height of bar
        //canvasDrawSquare(10, 150, 40, 150-average*3);

        //Draw circle
        canvasDrawCircle(average + 50);
      };

      // stream -> mediaSource -> analyser -> javascriptNode -> destination
      mediaStreamSource.connect(analyser);
      analyser.connect(javascriptNode);
      javascriptNode.connect(context.destination);
    }

    function onError() {
      alert('Error');
    }

    if(navigator.getUserMedia) {
      navigator.getUserMedia({video: false, audio: true}, onSuccess, onError);
    } else if(navigator.webkitGetUserMedia) {
      navigator.webkitGetUserMedia({video: false, audio: true}, onSuccess, onError);
    }

  // THIS IS FOR RECORDING, MAYBE EVENTUALLY
  // function record() {
  //   navigator.getUserMedia({audio: true}, function(localMediaStream){
  //     mediaStream = localMediaStream;
  //     var mediaStreamSource = context.createMediaStreamSource(localMediaStream);
  //     rec = new Recorder(mediaStreamSource, {
  //       workerPath: '/app/assetes/javascripts/recorderWorker.js'
  //     });
  //
  //     rec.record();
  //   }, function(err){
  //     console.log('Not supported');
  //   });
  // }
  //
  // function stop() {
  //   mediaStream.stop();
  //   rec.stop();
  //
  //   rec.exportWAV(function(e){
  //     rec.clear();
  //     Recorder.forceDownload(e, "test.wav");
  //   });
  // }

});


</script>
